{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80bf551-ec6e-4f17-8572-d8722a1d073f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install pandas transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf62fa68-a3b3-460a-88a2-6f03bee74a73",
   "metadata": {},
   "source": [
    "Special install of pytorch for apple sillicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e0321-ce77-4304-9fa1-ca6e52bda662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ccceb2-00cf-48dd-aed6-6ead228078ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fee29b7-c030-4357-9a2d-9bf194b1c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Parse the CSV\n",
    "# =================================\n",
    "\n",
    "# Load the CSV file with categories and identifiers\n",
    "categories = pd.read_csv('hierarchy/FoR_code_hierarchical_4_digit.csv')\n",
    "\n",
    "# Load the CSV file with papers to be identified\n",
    "papers = pd.read_csv('sample_data/dev_sample.csv')\n",
    "\n",
    "# Display the DataFrame to understand its structure\n",
    "# categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2a1aa-1108-45f3-826d-7d0f7ab37686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Build the Hierarchical Structure with Identifiers\n",
    "hierarchy_with_ids = utils.build_hierarchy_with_ids(categories)\n",
    "#print(hierarchy_with_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3241215-f9b3-43e9-8d87-b2b31bcc13a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Initialize the Hugging Face Model\n",
    "# ==========================================\n",
    "\n",
    "# Load the Hugging Face model for classification\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      #model=\"facebook/bart-large-mnli\")\n",
    "                      model=\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\",device = \"mps\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7305a2c0-fa18-4532-ba49-cfcdd4798ec5",
   "metadata": {},
   "source": [
    "def classify_text_with_ids(text, classifier, node, threshold=0.7):\n",
    "    print(f\"Classifying at level: {list(node.keys())}\")\n",
    "\n",
    "    # Classify text at the current node level with multi-label classification\n",
    "    labels = list(node.keys())\n",
    "    predictions = classifier(text, candidate_labels=labels, multi_label=True)\n",
    "\n",
    "    # Display raw predictions for clarity\n",
    "    print(f\"Raw predictions: {dict(zip(predictions['labels'], predictions['scores']))}\")\n",
    "\n",
    "    # Normalize probabilities by the top prediction\n",
    "    max_score = max(predictions['scores'])\n",
    "    normalized_scores = [score / max_score for score in predictions['scores']]\n",
    "\n",
    "    # Display normalized scores for clarity\n",
    "    print(f\"Normalized scores: {dict(zip(predictions['labels'], normalized_scores))}\")\n",
    "\n",
    "    # Filter candidates above the threshold\n",
    "    valid_candidates = [\n",
    "        (predictions['labels'][i], predictions['scores'][i])\n",
    "        for i in range(len(labels))\n",
    "        if normalized_scores[i] >= threshold\n",
    "    ]\n",
    "\n",
    "    print(f\"Valid candidates above threshold {threshold}: {valid_candidates}\")\n",
    "\n",
    "    results = []\n",
    "    for label, score in valid_candidates:\n",
    "        child_node = node[label]\n",
    "        print(f\"Processing label: '{label}' with score: {score:.4f}\")\n",
    "\n",
    "        if child_node['children']:  # Reclassify at the lower level\n",
    "            print(f\"Descending into children of '{label}'\")\n",
    "            sub_results = classify_text_with_ids(text, classifier, child_node['children'], threshold)\n",
    "            # Multiply probabilities (naive Bayes style)\n",
    "            for sub_label, sub_prob, sub_path in sub_results:\n",
    "                combined_prob = score * sub_prob\n",
    "                combined_path = f\"{label} -> {sub_label}\"\n",
    "                results.append((combined_path, combined_prob, [label] + sub_path))\n",
    "                print(f\"  Combined result: {combined_path} with probability {combined_prob:.4f}\")\n",
    "        else:\n",
    "            results.append((label, score, [label]))\n",
    "            print(f\"Final result at leaf node: {label} with probability {score:.4f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bcfce-f4dd-4bdd-b05a-3ef173219f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_with_ids(text, classifier, node, threshold=0.7, n_max=None):\n",
    "    # Step 1: Classify text at the current node level with multi-label classification\n",
    "    labels = list(node.keys())\n",
    "    predictions = classifier(text, candidate_labels=labels, multi_label=True)\n",
    "\n",
    "    # Normalize probabilities by the top prediction\n",
    "    max_score = max(predictions['scores'])\n",
    "    normalized_scores = [score / max_score for score in predictions['scores']]\n",
    "\n",
    "    # Filter candidates above the threshold\n",
    "    valid_candidates = [\n",
    "        (predictions['labels'][i], predictions['scores'][i])\n",
    "        for i in range(len(labels))\n",
    "        if normalized_scores[i] >= threshold\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for label, score in valid_candidates:\n",
    "        child_node = node[label]\n",
    "        if child_node['children']:  # Reclassify at the lower level\n",
    "            sub_results = classify_text_with_ids(text, classifier, child_node['children'], threshold)\n",
    "            # Multiply probabilities (naive Bayes style)\n",
    "            for sub_label, sub_prob, sub_path in sub_results:\n",
    "                results.append((f\"{label} -> {sub_label}\", score * sub_prob, [label] + sub_path))\n",
    "        else:\n",
    "            results.append((label, score, [label]))\n",
    "\n",
    "    # Step 2: Final pass over all combined answers\n",
    "    if results:\n",
    "        # Find the maximum probability from the combined results\n",
    "        max_combined_prob = max(result[1] for result in results)\n",
    "\n",
    "        # Filter out results with probabilities below threshold * max_combined_prob\n",
    "        filtered_results = [\n",
    "            result for result in results\n",
    "            if result[1] >= threshold * max_combined_prob\n",
    "        ]\n",
    "\n",
    "        # Sort the results by probability in descending order\n",
    "        filtered_results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Cut to the top n_max results if specified\n",
    "        if n_max is not None:\n",
    "            filtered_results = filtered_results[:n_max]\n",
    "\n",
    "        results = filtered_results\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba1701-f6b6-45d4-8b86-95a634cdd065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#title = \"From Maladaptation to Competition to Cooperation in the Evolution of Musical Behaviour\"\n",
    "#journal = \"Musicae Scientiae\"\n",
    "#title = \"Protruding masticatory (superfast) myosin heads from staggered thick filaments of dog jaw muscle revealed by X-ray diffraction\"\n",
    "#journal = \"Journal of Biochemistry\"\n",
    "title = \"Characterising infant and young child feeding practices and the consumption of poultry products in rural Tanzania: A mixed methods approach\"\n",
    "journal = \"Maternal and Child Nutrition\"\n",
    "abstract = \"Suboptimal breastfeeding practices, early initiation of complementary feeding, and monotonous cereal-based diets have been implicated as contributors to continuing high rates of child undernutrition in sub-Saharan Africa. Nutrition-sensitive interventions, including agricultural programs that increase access to nutrient-rich vegetables, legumes, and animal-source foods, have the potential to achieve sustainable improvements in children's diets. In the quest to evaluate the efficacy of such programs in improving growth and development in the first 2 years of life, there is a role for mixed methods research to better understand existing infant and young child feeding practices. This analysis forms part of a longitudinal study assessing the impact of improvements to poultry health and crop production on diets and growth of 503 randomly selected children from eight rural communities in Manyoni District in central Tanzania. Using an explanatory sequential design, the quantitative phase of data collection was conducted between May 2014 and May 2016, comprising six monthly structured questionnaires, four monthly household-level documentation of chicken and egg consumption, and fortnightly records of children's breastfeeding status. The subsequent qualitative phase involved in-depth interviews with a subset of 39 mothers in October 2016. Breastfeeding was almost universal (96.8%) and of long duration (mean = 21.7 months, SD = 3.6), but early initiation of complementary feeding was also common (74.4%; mean = 4.0 months, SD = 1.8), overwhelmingly driven by maternal perceptions of insufficient milk supply (95.0%). Chicken and eggs were infrequently eaten, but close associations between maternal and child consumption patterns (p <.001) suggest the potential for strategies that increase household-level consumption to bring nutritional benefits to young children.\"\n",
    "\n",
    "def tst_fnc():\n",
    "    #query = \"Journal: \"+journal+\", Title: \"+physics_paper\n",
    "    #query = \"Journal: \"+journal+\", Title: \"+title\n",
    "    query = title\n",
    "    #query = title + \". Abstract: \"+ abstract\n",
    "    #query = \"Journal: \"+journal+\", Title: \"+title+\", Abstract: \"+ abstract\n",
    "    #query = \"Abstract: \"+ abstract+\", Title: \"+title+\", Journal: \"+journal\n",
    " #   return classify_text_with_ids(query, classifier, hierarchy_with_ids,threshold=0.3,n_max=10)\n",
    "    return classify_text_with_ids(query, classifier, hierarchy_with_ids,threshold=0.7)\n",
    "\n",
    "#elapsed_time = timeit.timeit(tst_fnc, number=1)\n",
    "#print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "result = tst_fnc()\n",
    "# Display the results\n",
    "print(\"Final Classification Results:\")\n",
    "print([item[2] + [ round(item[1],ndigits=3) ] for item in result])\n",
    "\n",
    "#for path, prob, hierarchy_path in result:\n",
    "#    print(f\"Path: {path}, Probability: {prob:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a3335-264c-4c83-a6d9-42a7d85d1feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539dcaaf-15a4-4f69-b63d-9be5a3083c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "[item[2] + [ round(item[1],ndigits=3) ] for item in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0bf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
